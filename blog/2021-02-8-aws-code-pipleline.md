Prerequisites

Before getting started, you must have the following prerequisites:

    AWS accounts:
        Tenant – The dedicated account for the tenant, called msw.
        Cloud formation templates generated by Hamlet.

    Install and authenticate the AWS CLI. You can authenticate with an AWS Identity and Access Management (IAM) user or an AWS Security Token Service (AWS STS) token.
    Install Git.

Setting up the Git repository

Your first step is to set up your Git repository.

Create a Github repository to host the source code.

The CI/CD pipeline is automatically triggered every time new code is pushed to that repository.

Make sure Git is configured to use IAM credentials to access AWS CodeCommit via HTTP by running the following command from the terminal:

Bash
    Clone the newly created repository locally, and the build file
       
Resources:
    DocsApplication:
        phases:
            install:
                runtime-versions:
                    nodejs: 12
            commands:
                - touch .npmignore
                - cd $CODEBUILD_SRC_DIR/website/my-mdx-starter && npm install -g gatsby-cli

YAML

Push file to the remote Git repository.

Creating the artifact store encryption key

By default, CodePipeline uses server-side encryption with an AWS Key Management Service (AWS KMS) managed customer master key (CMK) to encrypt the release artifacts. Because the msw account need to decrypt those release artifacts, you need to create a customer managed CMK in the account ID.

From the terminal, run the following command to create the artifact encryption key:

aws kms create-key --region <YOUR_REGION>

Bash

    This command returns a JSON object with the key ARN property if run successfully. Its format is similar to arn:aws:kms:<YOUR_REGION>:<TENANt_ACCOUNT_ID>:key/<KEY_ID>. Record this value to use in the following steps.

The encryption key has been created manually here, but it’s has to be part of the hamlet blueprint.

Creating an Amazon S3 artifact store and configuring a bucket policy

In this case uses Amazon Simple Storage Service (Amazon S3) as artifact store. Every release artifact is encrypted and stored as an object in an S3 bucket.

To create and configure the artifact store, follow these steps in the account:

From the terminal, create an S3 bucket and give it a unique name:

aws s3api create-bucket \
    --bucket <BUCKET_UNIQUE_NAME> \
    --region <YOUR_REGION> \
    --create-bucket-configuration LocationConstraint=<YOUR_REGION>

Bash

    Configure the bucket to use the customer managed CMK created in the previous step. This makes sure the objects stored in this bucket are encrypted using that key, replacing <KEY_ARN> with the ARN property from the previous step:

aws s3api put-bucket-encryption \
    --bucket <BUCKET_UNIQUE_NAME> \
    --server-side-encryption-configuration \
        '{
            "Rules": [
                {
                    "ApplyServerSideEncryptionByDefault": {
                        "SSEAlgorithm": "aws:kms",
                        "KMSMasterKeyID": "<KEY_ARN>"
                    }
                }
            ]
        }'


Bash

    Create an IAM policy that grants access to the artifact store S3 bucket and to the artifact encryption key:

aws iam create-policy \
    --policy-name CodePipelineArtifactReadPolicy \
    --profile <TENANT_PROFILE_NAME> \
    --policy-document \
        '{
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": [
                        "s3:GetBucket*",
                        "s3:ListBucket"
                    ],
                    "Resource": [
                        "arn:aws:s3:::<BUCKET_UNIQUE_NAME>"
                    ],
                    "Effect": "Allow"
                },
                {
                    "Action": [
                        "s3:GetObject*",
                        "s3:Put*"
                    ],
                    "Resource": [
                        "arn:aws:s3:::<BUCKET_UNIQUE_NAME>/AccountPipeline/*"
                    ],
                    "Effect": "Allow"
                },
                {
                    "Action": [ 
                        "kms:DescribeKey", 
                        "kms:GenerateDataKey*", 
                        "kms:Encrypt", 
                        "kms:ReEncrypt*", 
                        "kms:Decrypt" 
                    ], 
                    "Resource": "<KEY_ARN>",
                    "Effect": "Allow"
                }
            ]
        }'

Bash

    Create an IAM policy that allows to pass the IAM role CloudFormationDeploymentRole to CloudFormation and to perform CloudFormation actions on the application Stack:

aws iam create-policy \
    --policy-name CodePipelinecfPolicy \
    --profile <TENANT_PROFILE_NAME> \
    --policy-document \
        '{
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Action": [
                        "iam:PassRole"
                    ],
                    "Resource": "arn:aws:iam::<TENANT_ACCOUNT_ID>:role/CloudFormationDeploymentRole",
                    "Effect": "Allow"
                },
                {
                    "Action": [
                        "cloudformation:*"
                    ],
                    "Resource": "arn:aws:cloudformation:<YOUR_REGION>:<TENANT_ACCOUNT_ID>:stack/DocsApplication*/*",
                    "Effect": "Allow"
                }
            ]
        }'

Bash

    Attach the CodePipelinecfPolicy IAM policy to the CodePipelineAccountRole IAM role:

aws iam attach-role-policy \
    --profile <TENANT_PROFILE_NAME> \
    --role-name CodePipelineAccountRole \
    --policy-arn arn:aws:iam::<TENANT_ACCOUNT_ID>:policy/CodePipelinecfPolicy

Bash

Building the ennivronemnt cloudforamtion templates triggering AWS codebuild configured

version: 0.2

#run-as: hamlet
env:
  git-credential-helper: yes
  
  variables:
    ACCOUNT: gsha01
    PRODUCT: igldocs
    
    PRODUCT_INFRASTRUCTURE_REFERENCE: master
    PRODUCT_CONFIG_REFERENCE: master
    MODE: update
    AUTODEPLOY: yes
    GENERATION_LOG_LEVEL: debug
    ENVIRONMENT: integration 
    SEGMENT: default

    DEPLOYMENT_UNITS: baseline, docs-v1
    IMAGE_FORMATS: spa

phases:
  install:
    commands:
      - echo installing go code
  pre_build:
    commands:
      - echo Update Build Refs
      - GIT_COMMIT=$CODEBUILD_RESOLVED_SOURCE_VERSION
      - REPO_URL=$CODEBUILD_SOURCE_REPO_URL
      - REPO_DIR=${CODEBUILD_SRC_DIR}
      - echo $GIT_COMMIT
      - echo $REPO_URL
      - echo $IMAGE_FORMATS
      - CODE_COMMIT_LIST=$GIT_COMMIT
      - DEPLOYMENT_UNIT_LIST=$DEPLOYMENT_UNITS
      - RELEASE_MODE=$MODE
      - ACCEPTANCE_TAG=$AUTODEPLOY
      - PRODUCT_DIR=$CODEBUILD_SRC_DIR
      - cd ${CODEBUILD_SRC_DIR}/${PRODUCT}/config/solutionsv2/${ENVIRONMENT}/default
      - cd ${CODEBUILD_SRC_DIR}/${PRODUCT} && ${GENERATION_DIR}/setup.sh 
      - ${AUTOMATION_DIR}/validateUpdateBuildReferencesParameters.sh 
      - ${AUTOMATION_DIR}/confirmBuilds.sh
      
  build:
    commands:
      - echo Building the Go code...
      - DEPLOYMENT_UNIT_LIST=docs-v1
      - REPO_DIR=${CODEBUILD_SRC_DIR}
      - for value in $DEPLOYMENT_UNIT_LIST;
          do
            echo $value;
          done
      - echo run the next command
   
  post_build:
    commands:
      - echo post Building the Go code...

Creating a deployment IAM role in tenant account

After CodePipeline assumes the CodePipelineAccountRole IAM role into the tenant account, it triggers cloudformation to provision the infrastructure based on the template defined in the cmdb cloudformation yaml file. For that, AWS CloudFormation needs to assume an IAM role that grants privileges to create resources into the tenant AWS account.


Create an IAM role that can be assumed by AWS CloudFormation:

aws iam create-role \
    --role-name CloudFormationDeploymentRole \
    --profile <TENANT_PROFILE_NAME> \
    --assume-role-policy-document \
        '{
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Principal": {
                        "Service": "cloudformation.amazonaws.com"
                    },
                    "Action": "sts:AssumeRole"
                }
            ]
        }'



Create an IAM policy that grants permissions to create AWS resources:


The granted permissions in this IAM policy depend on the resources the application needs to be provisioned. Because the application in our use case consists of a simple doc site, the IAM policy only needs permissions over S3 bucket. Use AWS CodeDeploy to deploy the website.

    Attach the IAM policy to the IAM role:

aws iam attach-role-policy \
    --profile <TENANT_PROFILE_NAME> \
    --role-name CloudFormationDeploymentRole \
    --policy-arn arn:aws:iam::<TENANT_ACCOUNT_ID>:policy/CloudFormationDeploymentPolicy


Bash
Provisioning the CI/CD pipeline

Each CodePipeline workflow consists of two or more stages, which are composed by a series of parallel or serial actions. For our use case, the pipeline is made up of four stages:

    Source – Declares GITHUB as the source control for the application code.
    Build – Using CodeBuild, it installs the dependencies and builds deployable artifacts. In this use case, the sample application is too simple and this stage is used for illustration purposes.
    Deploy_Dev – Deploys the sample application on a sandbox environment. At this point, the deployable artifacts generated at the Build stage are used to create a CloudFormation stack and deploy the website.

To provision your resources, complete the following steps from the terminal:

    Download the CloudFormation pipeline template:

curl -LO https://{account}-saas.s3.amazonaws.com/pipeline.yaml

Bash

    Deploy the CloudFormation stack using the pipeline template:

aws cloudformation deploy \
    --template-file pipeline.yaml \
    --region <YOUR_REGION> \
    --stack-name <YOUR_PIPELINE_STACK_NAME> \
    --capabilities CAPABILITY_IAM \
    --parameter-overrides \
        ArtifactBucketName=<BUCKET_UNIQUE_NAME> \
        ArtifactEncryptionKeyArn=<KMS_KEY_ARN> \
        mswAccountId=<msw_TENANT_ACCOUNT_ID> \
        DocsApplicationRepositoryName=<YOUR_CODECOMMIT_REPOSITORY_NAME> \
        RepositoryBranch=<YOUR_CODECOMMIT_MAIN_BRANCH>

Bash

This is the list of the required parameters to deploy the template:

        ArtifactBucketName – The name of the S3 bucket where the deployment artifacts are to be stored.
        ArtifactEncryptionKeyArn – The ARN of the customer managed CMK to be used as artifact encryption key.
        mswAccountId – The AWS account ID for the first tenant (msw) where the application is to be deployed.
        RepositoryName – The name of the CodeCommit repository where source changes are detected.
        RepositoryBranch – The name of the CodeCommit branch where source changes are detected. The default value is master in case no value is provided.

    Wait for AWS CloudFormation to create the resources.

When stack creation is complete, the pipeline starts automatically.

The code declares two IAM roles. The first one is the IAM role assumed by the CodePipeline action to access the tenant AWS account, whereas the second is the IAM role used by AWS CloudFormation to create AWS resources in the tenant AWS account. The ParameterOverrides configuration declares where the release artifact is located. 

Besides the CI/CD pipeline itself, this CloudFormation template declares IAM roles that are used by the pipeline and its actions. The main IAM role is named AccountPipelineRole, which is used by the CodePipeline service. It contains permissions to assume the action roles. See the following code:

{
    "Action": "sts:AssumeRole",
    "Effect": "Allow",
    "Resource": [
        "arn:aws:iam::<ACCOUNT_ID>:role/<PipelineSourceActionRole>",
        "arn:aws:iam::<ACCOUNT_ID>:role/<PipelineApplicationBuildActionRole>",
        "arn:aws:iam::<ACCOUNT_ID>:role/<PipelineDeployDevActionRole>",
        "arn:aws:iam::<msw_ACCOUNT_ID>:role/CodePipelineAccountRole",
    ]
}

JSON

When you have more tenant accounts, you must add additional roles to the list.

After CodePipeline runs successfully, test the sample application by invoking the S3 bucket URL on tenant account:


Cleaning up

Follow these steps to delete the components and avoid future incurring charges:

    Delete the production application stack from each tenant account:

aws cloudformation delete-stack --profile <TENANT_PROFILE_NAME> --region <YOUR_REGION> --stack-name DocsApplication-<TENANT_NAME>-stack-<YOUR_REGION>

Bash

    Delete the dev application stack from the account:

aws cloudformation delete-stack --region <YOUR_REGION> --stack-name DocsApplication-dev-stack-<YOUR_REGION>

Bash

    Delete the pipeline stack from the account:

aws cloudformation delete-stack --region <YOUR_REGION> --stack-name <YOUR_PIPELINE_STACK_NAME>

Bash

    Delete the customer managed CMK from the account:

aws kms schedule-key-deletion --region <YOUR_REGION> --key-id <KEY_ARN>

Bash

    Delete the S3 bucket from the account:

aws s3 rb s3://<BUCKET_UNIQUE_NAME> --force

Bash

    Optionally, delete the IAM roles and policies you created in the tenant accounts

Conclusion

